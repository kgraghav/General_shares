{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Stock Market Data to Build a Portfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze share price data from various listings to answer the following questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What kind of gains do we expect from the various listings? <br>\n",
    "2. How do the price gains of the different listings correlate to each other? <br>\n",
    "3. What is the estimated listing price/stock at a future date (prediction)? <br>\n",
    "4. What kind of volatility do the listings have? <br>\n",
    "5. How can we use our analysis to form a balanced investment portfolio? <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Methodology:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import and organize data for the various listings <br>\n",
    "2. Make observations about the data <br>\n",
    "3. Use these observations to answer the questions <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Share price information obtained from: [Yahoo Finance](https://finance.yahoo.com/) <br>\n",
    "Link to Blogpost: [An Investing Newbie's Tryst with DataÂ Science](https://medium.com/@kgraghav/an-investing-newbies-tryst-with-data-science-241737102a6a) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below are the inputs to perform the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_list='AAPL FB NVDA TSLA FCAU F AAL UAL INO MVIS'  # List of \"listings\" to be analyzed\n",
    "total_investment=10000  # Total investment value in USD\n",
    "sample_interval ='1d'  # Time interval to fetch data at\n",
    "start='2019-09-10'  # Start date of interest\n",
    "end='2020-09-09'  # End period of interest\n",
    "resample_interval='3d'  # Upsampling/Downsampling interval (determined through trial and error)\n",
    "datetime_query=['09/21/2020','10/21/2021'] # Datetime query values (for prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>For this analysis, we look at the following listings (from different industries): </b> <br>\n",
    "<table style=\"width:100%\">\n",
    "  <tr><tr align=\"Center\">\n",
    "    <th>Listed Name</th>\n",
    "    <th>Company Name</th>\n",
    "    <th>Industry</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <tr align=\"Center\">\n",
    "    <td>AAPL</td>\n",
    "    <td>Apple</td>\n",
    "    <td>Technology</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <tr align=\"Center\">\n",
    "    <td>FB</td>\n",
    "    <td>Facebook</td>\n",
    "    <td>Technology</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <tr align=\"Center\">\n",
    "    <td>NVDA</td>\n",
    "    <td>NVDIA</td>\n",
    "    <td>Technology</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <tr align=\"Center\">\n",
    "    <td>TSLA</td>\n",
    "    <td>Tesla</td>\n",
    "    <td>Auto (Electric)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <tr align=\"Center\">\n",
    "    <td>FCAU</td>\n",
    "    <td>FCA</td>\n",
    "    <td>Auto</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <tr align=\"Center\">\n",
    "    <td>F</td>\n",
    "    <td>Ford</td>\n",
    "    <td>Auto</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <tr align=\"Center\">\n",
    "    <td>AAL</td>\n",
    "    <td>American Airlines</td>\n",
    "    <td>Airline</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <tr align=\"Center\">\n",
    "    <td>UAL</td>\n",
    "    <td>United Airlines</td>\n",
    "    <td>Airline</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <tr align=\"Center\">\n",
    "    <td>INO</td>\n",
    "    <td>Inovio</td>\n",
    "    <td>Medical</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <tr align=\"Center\">\n",
    "    <td>MVIS</td>\n",
    "    <td>Microvision</td>\n",
    "    <td>Medical</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (20.2.3)\n"
     ]
    }
   ],
   "source": [
    "#Update python standard libraries install\n",
    "!pip install --upgrade pip\n",
    "\n",
    "# library to for array handling\n",
    "import numpy as np \n",
    "\n",
    "# library for dataframes\n",
    "import pandas as pd \n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Linear Model\n",
    "import sklearn as sk\n",
    "\n",
    "# Math Module\n",
    "import math\n",
    "\n",
    "# Matplotlib and associated plotting modules\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine-Learning and analysis modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Module to handle XML and HTML \n",
    "! pip install lxml;\n",
    "\n",
    "#Finance information import (Link in \"Yahoo Finance\" Markdown Cell in the \"References\" Section)\n",
    "!pip install yfinance;\n",
    "import yfinance as yf;\n",
    "\n",
    "print('Libraries imported.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data into DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create basic dataframe \"df_info\" containing all the available stocks information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of stock names as specified by the User\n",
    "s_list=s_list.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Basic Dataframe as empty\n",
    "df_info=pd.DataFrame() \n",
    "\n",
    "# Add Stocks information for List of stock names\n",
    "for item in s_list:\n",
    "    data=yf.Ticker(item)\n",
    "    df_data=data.history(period=sample_interval,start=start ,end=end )\n",
    "    df_data=df_data.reset_index()\n",
    "    df_data['Name']=pd.DataFrame([item for i in range(0,len(df_data))])\n",
    "    df_info=pd.concat([df_info,df_data])\n",
    "\n",
    "# Display basic information\n",
    "df_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size of Data:\n",
    "print('Size of the full dataset is: {} by {}'.format(df_info.shape[0],df_info.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Pre-Processing Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataframe (df) of Opening Price vs. date, which will be the data looked at in this analysis  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new Dataframe of Opening Stock Prices\n",
    "df=pd.DataFrame();\n",
    "for item in s_list:\n",
    "    df[['Date',item]]=df_info.loc[df_info['Name']==item,['Date','Open']]\n",
    "df=df.set_index('Date')\n",
    "df_price=df\n",
    "# Display initial few contents of the Dataset\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display basic information about this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic statistics of the opening prices\n",
    "# Darker cells denote higher values\n",
    "df.describe().style.background_gradient(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> A few notes and observations: </b> </br>\n",
    "1. All values in the \"count\" row are the same, implying there are no bad values (such as NaNs) <br>\n",
    "2. NVDIA and TESLA have some of the highest price fluctuations in absolute value based on their std. <br>\n",
    "3. The listings looked at in the tech. industry have some of the highest share prices, followed by the airline industry. The Auto industry is generally lower with the exception of Tesla, whose share price is on par with the tech. industry (what's different here?)<br>\n",
    "4. NVDIA and TESLA have seen some of the highest rises in absolute prices over the period <br>\n",
    "5. Inovio (medical industry) has the highest rise in percentage of initial price <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create basic Time plot to look at pertinent information (Opening price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Open price vs. Time\n",
    "ax= plt.subplot()\n",
    "for item in df_price.columns:\n",
    "    plt.plot(df_price[item])\n",
    "\n",
    "ax.legend(df_price.columns)\n",
    "plt.ylabel('Stock Price [USD]')\n",
    "ax.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Again a few things to note: </b><br>\n",
    "1. Tech industry stocks seem to follow a similar trend w.r.t. time <br>\n",
    "2. Tech industry stocks are seen to rise steadily. <br>\n",
    "3. All listings had a decline around the 2020-03 to 2020-04 timeframe. <br>\n",
    "4. Tech industry stocks rebounded back much better than the other industry listings after 2020-04. Tesla is the exception which more closely forllows the trends of the Tech. industry <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What kind of gains do we see with the various listings?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the opening price to determine % Gain over the period of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize w.r.t. start price (df_start) <br> \n",
    "Normalization used: (price-start_price)/start_price*100 to obtain df_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization Function\n",
    "def df_normalize(df):\n",
    "    df_strt=df.iloc[0,:]\n",
    "    df_norm=(df.iloc[:,:]-df_strt)/df_strt*100\n",
    "    df_strt=pd.DataFrame(df_strt).transpose()\n",
    "    df_strt=df_strt.set_axis(['start_price'])\n",
    "    return [df_norm,df_strt]\n",
    "\n",
    "# Store Normalized values in DataFrame and display results                          \n",
    "[df_norm,df_start]=df_normalize(df)\n",
    "df_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size of Data:\n",
    "print('Size of the data is: {} by {}'.format(df_norm.shape[0],df_norm.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic statistics of the normalized prices\n",
    "# Darker cells denote higher values\n",
    "df_norm.describe().style.background_gradient(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot trends in Normalized values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display % Growth over time\n",
    "ax= plt.subplot()\n",
    "for item in df_norm.columns:\n",
    "    plt.plot(df_norm[item])\n",
    "\n",
    "ax.legend(df.columns)\n",
    "plt.ylabel('Growth %')\n",
    "ax.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do the price gains of the listings correlate to each other?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df_norm.corr(),annot=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax= plt.subplot()\n",
    "for item in df_norm.columns:\n",
    "    plt.scatter(df_norm.iloc[:,0],df_norm[item])\n",
    "\n",
    "ax.legend(df_norm.columns)\n",
    "plt.xlabel('AAPL Growth %')\n",
    "plt.ylabel('Growth %')\n",
    "ax.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Observations:</b> <br>\n",
    "1. Best matches between various companies in the tech industry (and Tesla) <br>\n",
    "2. Worst matches between the tech industry and airline industry <br>\n",
    "3. Medical industry has intermediate match with the tech industry and bad match with the airline and auto industry<br>\n",
    "4. Auto and airline industries correlate well with each other <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some general observations and next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Time Data is too transient to determine good (suitably longer term) trends of rise and fall of prices <br>\n",
    "2. To alleviate this, the data is downsampled so that the transients are smoothed out and better estimates can be made for rise and fall trends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General approach to answer the remaining questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Downsample the data to smoothen it and obtain longer term trends in rise and fall of prices <br>\n",
    "2. Use the smoothened data to obtain price rise and price fall information <br>\n",
    "3. Use the standard deviation of the price rise/fall values to determine the price bounds  <br>\n",
    "4. Use the ratio of price bounds and the change in price, to estimate \"volatility\" <br>\n",
    "5. Create a linear regression fit object for the historical data over the period of analysis <br>\n",
    "6. Estimate the \"reward\" or slope of price change from the fit object <br>\n",
    "7. Plot the historical data along with the linear fit and price bounds to see how well the historical data falls within these margins <br>\n",
    "8. Estimate the \"returns_ratio\" as the ratio between the \"reward\" and \"volatility\" for each listing <br>\n",
    "9. The amount to invest in each listing is the weighted average of the \"returns_ratio\" multiplied by the total investment capital <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsample the data to filter out high frequency changes and determine pertinent trends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Downsampled normalized data  \"df_norm_resampled\"</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample with cubic interpolation\n",
    "df_norm_resampled=df_norm.resample(resample_interval).interpolate(method='cubic')\n",
    "df_norm_resampled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Downsampled normalized data statistics \"df_norm_resampled\" </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic downsampled statistics of normalized data\n",
    "df_norm_resampled.describe().style.background_gradient(axis=1).format(\"{:.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Downsampled price data </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample with cubic interpolation\n",
    "df_resampled=df.resample(resample_interval).interpolate(method='cubic')\n",
    "df_resampled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Downsampled price data statistics </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic downsampled statistics of normalized data\n",
    "df_resampled.describe().style.background_gradient(axis=1).format(\"{:.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Time plot of filtered price data</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax= plt.subplot()\n",
    "for item in df_resampled.columns:\n",
    "    plt.plot(df_resampled.index,df_resampled[item])\n",
    "\n",
    "ax.legend(df_resampled.columns)\n",
    "plt.ylabel('Price USD')\n",
    "ax.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are able to sufficiently capture trends now after the filtering.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Time, percent and absolute rise and fall of Growth "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. \"df_norm_resampled_rise_fall\" is the dataframe of the normalized rise and fall prices <br>\n",
    "2. \"df_norm_resampled_rise_fall_time\" is the dataframe of the rise and fall times of the normalized changes <br>\n",
    "3. \"df_norm_resampled_rise_fall_prices\" is the dataframe of the rise and fall prices, calculated from the normalized values and the start value <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to calculate rise and fall: rise_fall_stat(df,item)\n",
    "# \"item\" is a list of columns of the price dataframe\n",
    "def rise_fall_stat(df,item):\n",
    "    #Initialize rise and fall arrays\n",
    "    rise=np.array([])        \n",
    "    fall=np.array([])\n",
    "    rise_t=np.array([])        \n",
    "    fall_t=np.array([])\n",
    "    # if df[i]-df[i-1] is positive, \n",
    "    # add that to rise and add the time delta to rise_time\n",
    "    # else if negative, add that (absolute) to fall, and add the time delta to fall_time\n",
    "    # else move to next point\n",
    "    i=1\n",
    "    while i<len(df)-1:\n",
    "        rise_val=0\n",
    "        fall_val=0\n",
    "        rise_time=0\n",
    "        fall_time=0\n",
    "        try:\n",
    "            while df.iloc[i]>df.iloc[i-1] and i<len(df)-1:\n",
    "                rise_val=rise_val+(df.iloc[i]-df.iloc[i-1])\n",
    "                rise_time=rise_time+((df.index[i]-df.index[i-1]).value)\n",
    "                i=i+1\n",
    "            rise=np.append(rise,rise_val)\n",
    "            rise_t=np.append(rise_t,rise_time)\n",
    "        except:\n",
    "            print('{} error at: {}, {}'.format(e,item,i))\n",
    "        try:\n",
    "            while df.iloc[i]<df.iloc[i-1] and i<len(df)-1:\n",
    "                fall_val=fall_val+(df.iloc[i-1]-df.iloc[i])\n",
    "                fall_time=fall_time+((df.index[i]-df.index[i-1]).value)\n",
    "                i=i+1\n",
    "            fall=np.append(fall,fall_val)\n",
    "            fall_t=np.append(fall_t,fall_time)\n",
    "        except:\n",
    "            print('{} error at: {}, {}'.format(e,item,i))\n",
    "        i=i+1\n",
    "    # Estimate statistics for rise and fall arrays and create a dataframe for it\n",
    "    df_rise_fall=pd.DataFrame({'%_rise_mean': [np.mean(rise)],'%_fall_mean': [np.mean(fall)],\n",
    "                               '%_rise_min': [np.min(rise)],'%_fall_min': [np.min(fall)],\n",
    "                               '%_rise_max': [np.max(rise)],'%_fall_max': [np.max(fall)],\n",
    "                               '%_rise_std': [np.std(rise)],'%_fall_std': [np.std(fall)]}).transpose()\n",
    "    df_rise_fall=df_rise_fall.rename(columns={0:item})\n",
    "    # Estimate statistics for rise and fall arrays and create a dataframe for it\n",
    "    df_rise_fall_time=pd.DataFrame({'time_rise_mean': pd.to_timedelta([np.mean(rise_t)]).days,\n",
    "                                    'time_fall_mean': pd.to_timedelta([np.mean(fall_t)]).days,\n",
    "                               'time_rise_min': pd.to_timedelta([np.min(rise_t)]).days,\n",
    "                                    'time_fall_min': pd.to_timedelta([np.min(fall_t)]).days,\n",
    "                               'time_rise_max': pd.to_timedelta([np.max(rise_t)]).days,\n",
    "                                    'time_fall_max': pd.to_timedelta([np.max(fall_t)]).days,\n",
    "                               'time_rise_std': pd.to_timedelta([np.std(rise_t)]).days,\n",
    "                                    'time_fall_std': pd.to_timedelta([np.std(fall_t)]).days}).transpose()\n",
    "    df_rise_fall_time=df_rise_fall_time.rename(columns={0:item})\n",
    "    # Return rise, fall dataframes for price and time\n",
    "    return [df_rise_fall,df_rise_fall_time]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate rise and fall in gain % (w.r.t. initial price) for each listing using rise_fall_stat(...)\n",
    "df_norm_resampled_rise_fall=pd.DataFrame()\n",
    "df_norm_resampled_rise_fall_time=pd.DataFrame()\n",
    "# for each listing, obtain the rise and fall prices and times:\n",
    "for name in df_norm_resampled.columns:\n",
    "    df_norm_resampled_rise_fall=pd.concat([df_norm_resampled_rise_fall,rise_fall_stat(df_norm_resampled[name],name)[0]],axis=1)\n",
    "    df_norm_resampled_rise_fall_time=pd.concat([df_norm_resampled_rise_fall_time,rise_fall_stat(df_norm_resampled[name],name)[1]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display values for each listing. Darker cells denote larger values\n",
    "df_norm_resampled_rise_fall.style.background_gradient(axis=1).format(\"{:.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display values for each listing. Darker cells denote larger values\n",
    "df_norm_resampled_rise_fall_time.style.background_gradient(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert rise and fall from % to price (using price change= percent change/100*start price) and display.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('df_start={}'.format(df_start))\n",
    "df_norm_resampled_rise_fall_prices=pd.DataFrame(df_norm_resampled_rise_fall.values/100*df_start.values)\n",
    "# set appropriate index axis:\n",
    "df_norm_resampled_rise_fall_prices=df_norm_resampled_rise_fall_prices.set_axis(\n",
    "    [index.replace('%','price') for index in df_norm_resampled_rise_fall.index],\n",
    "                                                 axis=0).set_axis(df_norm_resampled_rise_fall.columns,axis=1)\n",
    "df_norm_resampled_rise_fall_prices.style.background_gradient(axis=1).format(\"{:.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a linear regression fit for the data with 3 std. of the maximum of rise and fall to determine the boundaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Linear Regression object, score and price boundaries for each listing </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_obj(df):\n",
    "    df_lin=df.iloc[0:1,:]\n",
    "    df_lin=df_lin.reindex(['fit_obj','score','price_bounds'])\n",
    "    for item in df_lin.columns:\n",
    "        price_bound=np.maximum(df_norm_resampled_rise_fall_prices.loc['price_rise_std',item],\n",
    "                                  df_norm_resampled_rise_fall_prices.loc['price_fall_std',item])*3\n",
    "        df_lin.loc['price_bounds',item]=price_bound\n",
    "        \n",
    "        # Implement train-test split thrice and fit the data to the average fit ...\n",
    "        # ... (intercept and coeff.) of the three splits\n",
    "        X=np.array(pd.to_numeric(df.index)).reshape(-1, 1)\n",
    "        Y=(df[item].values).reshape(-1, 1)\n",
    "        lin_list_coeff=[]\n",
    "        lin_list_intercept=[]\n",
    "        for i in range(0,2):\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33)\n",
    "            lin_obj=LinearRegression()\n",
    "            lin_obj.fit(X_train,y_train)\n",
    "            lin_list_coeff.append(lin_obj.coef_)\n",
    "            lin_list_intercept.append(lin_obj.intercept_)\n",
    "        linobj = LinearRegression()\n",
    "        linobj.coef_=np.array(np.array(lin_list_coeff).mean()).reshape(-1)\n",
    "        linobj.intercept_=np.array(np.array(lin_list_intercept).mean()).reshape(-1)\n",
    "        score=linobj.score(X,Y)\n",
    "        df_lin.loc['fit_obj',item]=linobj\n",
    "        df_lin.loc['score',item]=score\n",
    "        df_lin=df_lin.rename_axis(index='')\n",
    "        \n",
    "    return df_lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call lin_obj(...) to create the linear regression object dataframe\n",
    "df_price_est_obj=lin_obj(df)\n",
    "df_price_est_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate the price and bounds vs. date using the fit object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to estimate the price given the price dataframe, fit objects and datetime query\n",
    "def price_est(df,df_price_est_obj,datetime_query):\n",
    "    df_price_est=pd.DataFrame()\n",
    "    df_price_est=df_price_est.rename_axis(index='Datetime')\n",
    "    df_price_est['Datetime']=pd.to_datetime(datetime_query)\n",
    "    df_price_est=df_price_est.set_index('Datetime')\n",
    "    for item in df.columns:\n",
    "        fit_obj=df_price_est_obj.loc['fit_obj',item]\n",
    "        for datetime in df_price_est.index:\n",
    "            price_est=fit_obj.predict(np.array(datetime.value).reshape(-1,1))\n",
    "            df_price_est.loc[datetime,'{}'.format(item)]=price_est\n",
    "            df_price_est.loc[datetime,'{}_low'.format(item)]=price_est-(df_price_est_obj.loc['price_bounds',item])\n",
    "            df_price_est.loc[datetime,'{}_high'.format(item)]=price_est+(df_price_est_obj.loc['price_bounds',item])\n",
    "    df_price_est=df_price_est.reindex(df_price_est.index.date)\n",
    "    df_price_est=df_price_est\n",
    "    return df_price_est\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the predicted price/stock?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_price_est=price_est(df,df_price_est_obj,datetime_query)\n",
    "df_price_est.head().style.background_gradient(axis=1).format(\"{:.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What kind of volatility do we see in the stock prices?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do we generate our investment portfolio?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate the price history along with the bounds and plot the history and estimates for each listing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datetime history query values\n",
    "datetime_query_start_end=pd.date_range(start=start,end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and display estimates (listing, listing_low, listing_high)\n",
    "df_price_est_start_end=price_est(df,df_price_est_obj,datetime_query_start_end)\n",
    "df_price_est_start_end.head().style.background_gradient(axis=1).format(\"{:.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Open price vs. Time\n",
    "num_plot=len(df.columns)\n",
    "i=1\n",
    "for item in df.columns:\n",
    "    plt.figure()\n",
    "    plt.plot(df[item])\n",
    "    plt.plot(df_price_est_start_end[[item,item+'_low',item+'_high']])\n",
    "    plt.legend([item,item+'_predicted',item+'_low',item+'_high'])\n",
    "    plt.ylabel('Stock Price [USD]')\n",
    "    plt.grid(True)\n",
    "    #plt.ylim(0,700)\n",
    "    plt.title(item)\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing the Portfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to balance the investments, we'd want to have the most benefit (reward) while minimizing volatility (risk).<br>\n",
    "1. We can consider 'reward' to be the slope of the linear fit to share price (higher the slope, higher the gain).<br>\n",
    "2. We can consider 'risk' to be the ratio between the price bounds and change in price over the duration of interest <br>\n",
    "3. Hence we can compute a 'returns ratio' = 'reward'/'risk' for each listing; the higher this value, the more this investment is viable. <br>\n",
    "4. Then we can compute the sum of the returns ratios for each listing and divide the returns ratio by the summed value, to determine the \"weight\" of each investment <br>\n",
    "5. Finally we can multiply the \"weight\" by the total investment capital (total_investment) to obtain the recommended investment for each listing <br>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the Linear Regression object to construct the reward, volatility, returns ratio, weight and suggested investment values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the portfolio dataframe df_portfolio and update the index suitably\n",
    "df_portfolio=df_price_est_obj\n",
    "df_portfolio=df_portfolio.reindex(['reward','risk','returns_ratio','weight','suggested_investment'])\n",
    "df_portfolio=df_portfolio.rename_axis(index='Parameters')\n",
    "\n",
    "# Update \"reward\" using the slope of the line fit (multiplied by a suitable factor for display)\n",
    "for item in (df_portfolio.columns):\n",
    "    df_portfolio.loc['reward',item]=(df_price_est_obj.loc['fit_obj',item].coef_[0])*10**17\n",
    "    \n",
    "# Update the \"volatility\" as the ratio of the price bounds to the absolute net price change over the duration\n",
    "for item in (df_portfolio.columns):\n",
    "    df_portfolio.loc['risk',item]=(df_price_est_obj.loc['price_bounds',\n",
    "                                                              item])/abs(df_price_est_start_end.loc[df_price_est_start_end.index[-1],\n",
    "                                                                                                 item]-\n",
    "                                         df_price_est_start_end.loc[df_price_est_start_end.index[0],\n",
    "                                                                    item])\n",
    "                                         \n",
    "# Update the returns ratio as the ratio between the \"reward\" and \"volatility\"\n",
    "for item in (df_portfolio.columns):\n",
    "    df_portfolio.loc['returns_ratio',item]=(df_portfolio.loc['reward',item]/\n",
    "                                            df_portfolio.loc['risk',item])\n",
    "    \n",
    "# Remove those listings with negative returns_ratio since those imply a falling stock\n",
    "for item in df_portfolio.columns:\n",
    "    if df_portfolio.loc['reward',item]<=0:\n",
    "        df_portfolio.pop(item)\n",
    "        \n",
    "# Obtain the weighted average of the returns ratio for each listing\n",
    "for item in (df_portfolio.columns):\n",
    "    df_portfolio.loc['weight',item]=df_portfolio.loc['returns_ratio',item]/df_portfolio.loc['returns_ratio',:].sum()\n",
    "\n",
    "# Multiply the weight of each listing by the total investment capital to obtain the recommended investment\n",
    "for item in (df_portfolio.columns):\n",
    "    df_portfolio.loc['suggested_investment',item]=df_portfolio.loc['weight',item]*total_investment\n",
    "\n",
    "# Display the portfolio dataframe\n",
    "df_portfolio.style.background_gradient(axis=1).format(\"{:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What kind of volatility do the listings have?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Refer the \"volatility\" row, higher the value, greater the volatility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do we use the data to construct our portfolio?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer the dataframe \"df_portfolio\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
